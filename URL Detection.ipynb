{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import sys\n",
    "import os\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn import neighbors\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt \n",
    "import math\n",
    "from collections import Counter\n",
    "\n",
    "\n",
    "def getTokens(input):\n",
    "    tokensBySlash = str(input.encode('utf-8')).split('/')\t#get tokens after splitting by slash\n",
    "    allTokens = []\n",
    "    for i in tokensBySlash:\n",
    "        tokens = str(i).split('-')\t#get tokens after splitting by dash\n",
    "        tokensByDot = []\n",
    "        for j in range(0,len(tokens)):\n",
    "            tempTokens = str(tokens[j]).split('.')\t#get tokens after splitting by dot\n",
    "            tokensByDot = tokensByDot + tempTokens\n",
    "        allTokens = allTokens + tokens + tokensByDot\n",
    "    allTokens = list(set(allTokens))\t#remove redundant tokens\n",
    "    if 'com' in allTokens:\n",
    "        allTokens.remove('com')\t#removing .com since it occurs a lot of times and it should not be included in our features\n",
    "    return allTokens\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['diaryofagameaddict.com', 'espdesign.com.au', 'iamagameaddict.com', 'kalantzis.net', 'slightlyoffcenter.net']\n",
      "['bad', 'bad', 'bad', 'bad', 'bad']\n",
      "  (0, 421327)\t0.3228948635275226\n",
      "  (0, 189967)\t0.6692304935922834\n",
      "  (0, 189966)\t0.6692304935922834\n",
      "  (1, 201616)\t0.6188117984272429\n",
      "  (1, 123449)\t0.4838841971530818\n",
      "  (1, 201615)\t0.6188117984272429\n",
      "  (2, 232080)\t0.6692304935922834\n",
      "  (2, 232081)\t0.6692304935922834\n",
      "  (2, 421327)\t0.3228948635275226\n",
      "  (3, 246139)\t0.6416473265057543\n",
      "  (3, 570231)\t0.4202111573673834\n",
      "  (3, 246138)\t0.6416473265057543\n",
      "  (4, 329332)\t0.6416473265057543\n",
      "  (4, 329331)\t0.6416473265057543\n",
      "  (4, 570231)\t0.4202111573673834\n",
      "  (5, 351083)\t0.6692304935922834\n",
      "  (5, 351082)\t0.6692304935922834\n",
      "  (5, 421327)\t0.3228948635275226\n",
      "  (6, 355332)\t0.6692304935922834\n",
      "  (6, 355333)\t0.6692304935922834\n",
      "  (6, 421327)\t0.3228948635275226\n",
      "  (7, 489343)\t0.5511086852728356\n",
      "  (7, 237555)\t0.5566321579392742\n",
      "  (7, 237557)\t0.6216428699540543\n",
      "  (8, 686638)\t0.1833584691193646\n",
      "  :\t:\n",
      "  (420459, 128074)\t0.5319049549741209\n",
      "  (420459, 33491)\t0.4097413825786242\n",
      "  (420459, 40963)\t0.41592678541933176\n",
      "  (420459, 42403)\t0.41941817721214536\n",
      "  (420459, 128070)\t0.43755439348761516\n",
      "  (420459, 1626)\t0.09396048537020021\n",
      "  (420460, 414136)\t0.62721627997457\n",
      "  (420460, 414134)\t0.5679408464978891\n",
      "  (420460, 142380)\t0.4960291340448751\n",
      "  (420460, 583797)\t0.16038087683404462\n",
      "  (420460, 1626)\t0.11079713687075789\n",
      "  (420461, 498555)\t0.6061140184643864\n",
      "  (420461, 498556)\t0.6061140184643864\n",
      "  (420461, 142380)\t0.4793405740736491\n",
      "  (420461, 583797)\t0.15498497224381017\n",
      "  (420461, 1626)\t0.10706944320036857\n",
      "  (420462, 686384)\t0.6061140184643864\n",
      "  (420462, 686385)\t0.6061140184643864\n",
      "  (420462, 142380)\t0.4793405740736491\n",
      "  (420462, 583797)\t0.15498497224381017\n",
      "  (420462, 1626)\t0.10706944320036857\n",
      "  (420463, 643294)\t0.6540508042589379\n",
      "  (420463, 643150)\t0.30351138329630595\n",
      "  (420463, 142380)\t0.5172510096056001\n",
      "  (420463, 509119)\t0.46103121230539995\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\GUNDEEP\\Anaconda3\\envs\\tf1\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9617923013806143\n",
      "[1 1 1 ... 1 1 1]\n",
      "['bad' 'good']\n",
      "# ------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "def TL():\n",
    "    allurls = r\"D:\\MAC University of Windsor\\data.csv\"\n",
    "    \n",
    "#     ',' is the seperator in here\n",
    "    allurlscsv = pd.read_csv(allurls,',',error_bad_lines = False)\n",
    "    allurlsdata = pd.DataFrame(allurlscsv)\n",
    "#     print(allurlsdata.head())\n",
    "    \n",
    "    allurlsdata = np.array(allurlsdata)\n",
    "#     print(allurlsdata)\n",
    "   # ------------------------------------------------------------------------------\n",
    "    \n",
    "    y = [d[1] for d in allurlsdata]\n",
    "    corpus = [d[0] for d in allurlsdata]\n",
    "    print(corpus[0:5])    \n",
    "    print(y[0:5])\n",
    "    \n",
    "    \n",
    "    vectorizer = TfidfVectorizer(tokenizer=getTokens)\n",
    "    X = vectorizer.fit_transform(corpus)\n",
    "    print(X)\n",
    "    # ---------------------------------Logistic Regression---------------------------------------------\n",
    "    \n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state = 42)\n",
    "    lgs = LogisticRegression()\n",
    "    lgs.fit(X_train, y_train)\n",
    "    \n",
    "    print(lgs.score(X_test,y_test))\n",
    "    \n",
    "    \n",
    "    labelEncoder = LabelEncoder()\n",
    "    y_train_new = labelEncoder.fit_transform(y_train)\n",
    "    y_test_new = labelEncoder.fit_transform(y_test)\n",
    "    print(y_train_new)\n",
    "    print(labelEncoder.classes_)\n",
    "    \n",
    "    print(\"# ------------------------------------------SCV------------------------------------\")\n",
    "   \n",
    "    svc_classifier = SVC(kernel = 'rbf', random_state = 42, probability = True, cache_size = 7000 )\n",
    "    svc_classifier.fit(X_train,y_train_new)\n",
    "    \n",
    "    print(svc_classifier.score(X_test, y_test_new))\n",
    "    \n",
    "    print(\"# ------------------------------------------KNN------------------------------------\")\n",
    "    \n",
    "    knn classifier\n",
    "    clf = neighbors.KNeighborsClassifier()\n",
    "    clf.fit(X_train,y_train_new)\n",
    "    accuracy = clf.score(X_train,y_train_new)\n",
    "    accuracy2 = clf.score(X_test,y_test_new)\n",
    "    print(accuracy2)\n",
    "        \n",
    "    \n",
    "\n",
    "TL()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
